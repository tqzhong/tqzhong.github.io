---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a second year postgraduate student from [School of EEIS](https://eeis.ustc.edu.cn/main.htm), [University of Science and Technology of China](https://www.ustc.edu.cn/). My research interest includes controllable text generation and large language models in natural language processing. 

I am advised by [Zhendong Mao](https://faculty.ustc.edu.cn/maozhendong/zh_CN/index.htm) of
[Laboratory for Future Networks(LFN)](https://lfn.ustc.edu.cn/main.htm), University of Science and Technology of China.

---
permalink: /
title: "Publications"
excerpt: "Publications"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
---
title: "Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time Controllable Text Generation"
collection: publications
permalink: /publication/Air-Decoding
excerpt: 'The work proposes a novel decoding-time-based controllable text generation framework, where we introduce an Attribute Distribution Reconstruction method to effectively overcome the problem of Attribute Collapse in traditional decoding-time-based CTG.'
date: 2023-10-08
venue: 'October 8'
paperurl: 'https://aclanthology.org/2023.emnlp-main.512.pdf'
citation: 'Zhong, Tianqi, et al. "Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time Controllable Text Generation." Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023.'
---
The work proposes a novel decoding-time-based controllable text generation framework, where we introduce an Attribute Distribution Reconstruction method to effectively overcome the problem of Attribute Collapse in traditional decoding-time-based CTG.

[Download paper here](https://aclanthology.org/2023.emnlp-main.512.pdf)

Recommended citation: Zhong, Tianqi, et al. "Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time Controllable Text Generation." Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023.

